{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "armed-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collected-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.make_data import autoregressive\n",
    "# from models.conformal import nonconformity, cover, ConformalForecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "honest-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_autoregressive_forecast_dataset(n_samples=100,\n",
    "                                             seq_len=100,\n",
    "                                             n_features=1,\n",
    "                                             X_mean=1,\n",
    "                                             X_variance=2,\n",
    "                                             noise_profile=None,\n",
    "                                             memory_factor=0.9,\n",
    "                                             mode=\"time-dependent\",\n",
    "                                             horizon=10):\n",
    "    total_seq_len = seq_len + horizon\n",
    "    # Create the input features of the generating process\n",
    "    X_gen = [np.random.normal(X_mean, X_variance, (total_seq_len,\n",
    "                                                   n_features))\n",
    "             for _ in range(n_samples)]\n",
    "    w = np.array([memory_factor ** k for k in range(total_seq_len)])\n",
    "\n",
    "    if noise_profile is None:\n",
    "        # default increasing noise profile\n",
    "        noise_profile = np.array(\n",
    "            [1 / (seq_len - 1) * k for k in range(total_seq_len)])\n",
    "\n",
    "    X = None  # X stores the time series values generated from features X_gen\n",
    "    if mode == \"noise-sweep\":\n",
    "        X = torch.FloatTensor(\n",
    "            [[(autoregressive(X_gen[k], w).reshape(total_seq_len, n_features) +\n",
    "               np.random.normal(0, noise_profile[u], (total_seq_len,\n",
    "                                                      n_features)))\n",
    "                  .reshape(total_seq_len, ) for k in range(n_samples)]\n",
    "             for u in range(len(noise_profile))])\n",
    "\n",
    "\n",
    "    elif mode == \"time-dependent\":\n",
    "        X = torch.FloatTensor(\n",
    "            [(autoregressive(X_gen[k], w)\n",
    "              .reshape(total_seq_len, n_features) + (\n",
    "                  torch.normal(mean=0.0, std=torch.tensor(noise_profile)))\n",
    "              .detach().numpy().reshape(-1, n_features)).reshape(\n",
    "                total_seq_len, )\n",
    "                for k in range(n_samples)])\n",
    "\n",
    "    # TODO clean up (un)squeezing.\n",
    "    Y = torch.FloatTensor(X[:, -horizon:])  # `horizon` of predictions\n",
    "    X = torch.nn.utils.rnn.pad_sequence(X[:, :-horizon],\n",
    "                                        batch_first=True).unsqueeze(dim=-1)\n",
    "    \n",
    "    print(X.size(), Y.size())\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X, Y)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "promising-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def nonconformity(output, target):\n",
    "    \"\"\"Measures the nonconformity between output and target time series.\"\"\"\n",
    "    # Average MAE loss for every step in the sequence.\n",
    "    return torch.nn.functional.l1_loss(output, target, reduction='none')\n",
    "\n",
    "\n",
    "def cover(pred, target):\n",
    "    # Returns True when the entire forecast fits into predicted conformal\n",
    "    # intervals.\n",
    "    # TODO joint vs independent coverage\n",
    "    return torch.all(\n",
    "        torch.logical_and(target >= pred[:, 0], target <= pred[:, 1])).item()\n",
    "\n",
    "\n",
    "class ConformalForecaster(nn.Module):\n",
    "    def __init__(self, embedding_size, input_size=1, output_size=1, horizon=1,\n",
    "                 error_rate=0.05):\n",
    "        super(ConformalForecaster, self).__init__()\n",
    "        # input_size indicates the number of features in the time series\n",
    "        # input_size=1 for univariate series.\n",
    "\n",
    "        # Encoder and forecaster can be the same (if embeddings are\n",
    "        # trained on `horizon`-step forecasts), but different models are\n",
    "        # possible.\n",
    "\n",
    "        # TODO try separate encoder and forecaster models.\n",
    "        # TODO try the RNN autoencoder trained on reconstruction error.\n",
    "        self.encoder = None\n",
    "\n",
    "        self.forecaster_rnn = nn.LSTM(input_size=input_size,\n",
    "                                      hidden_size=embedding_size,\n",
    "                                      batch_first=True)\n",
    "        self.forecaster_out = nn.Linear(embedding_size, output_size)\n",
    "\n",
    "        self.horizon = horizon\n",
    "        self.alpha = error_rate\n",
    "\n",
    "        self.num_train = None\n",
    "        self.calibration_scores = None\n",
    "        self.critical_calibration_scores = None\n",
    "\n",
    "    def forward(self, x, len_x):\n",
    "        # len_x : torch.LongTensor\n",
    "        # \t\t  Length of sequences (b, )\n",
    "        sorted_len, idx = len_x.sort(dim=0, descending=True)\n",
    "        sorted_x = x[idx]\n",
    "\n",
    "        # Convert to packed sequence batch\n",
    "        packed_x = torch.nn.utils.rnn.pack_padded_sequence(sorted_x,\n",
    "                                                           lengths=sorted_len,\n",
    "                                                           batch_first=True)\n",
    "\n",
    "        # [batch, seq_len, embedding_size]\n",
    "        packed_h, _ = self.forecaster_rnn(packed_x)\n",
    "\n",
    "        max_seq_len = x.size(1)\n",
    "        padded_output, _ = torch.nn.utils.rnn.pad_packed_sequence(packed_h,\n",
    "                                                                  batch_first=True,\n",
    "                                                                  total_length=max_seq_len)\n",
    "\n",
    "        _, reverse_idx = idx.sort(dim=0, descending=False)\n",
    "        padded_output = padded_output[reverse_idx]\n",
    "\n",
    "        # [batch, horizon, output_size, 1]\n",
    "        return self.forecaster_out(\n",
    "            padded_output[:, -self.horizon:, :]).unsqueeze(-1)\n",
    "\n",
    "    def fit(self, dataset, calibration_dataset, epochs, lr, batch_size=150):\n",
    "        # Train the forecaster to return correct multi-step predictions.\n",
    "        train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True)\n",
    "        self.num_train = len(dataset)\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            train_loss = 0.\n",
    "\n",
    "            for sequences, targets in train_loader:  # iterate through batches\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                out = self(sequences)\n",
    "\n",
    "                loss = criterion(out, targets)\n",
    "                loss.backward()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "            mean_train_loss = train_loss / len(train_loader)\n",
    "            if epoch % 50 == 0:\n",
    "                print(\n",
    "                    'Epoch: {}\\tTrain loss: {}'.format(epoch, mean_train_loss))\n",
    "\n",
    "        # Collect calibration scores\n",
    "        self.calibrate(calibration_dataset)\n",
    "\n",
    "    def calibrate(self, calibration_dataset):\n",
    "        \"\"\"\n",
    "        Computes the nonconformity scores for the calibration dataset.\n",
    "        \"\"\"\n",
    "        calibration_loader = torch.utils.data.DataLoader(calibration_dataset,\n",
    "                                                         batch_size=1)\n",
    "        calibration_scores = []\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            self.eval()\n",
    "            for sequences, targets in calibration_loader:\n",
    "                out = self(sequences)\n",
    "                calibration_scores.extend(\n",
    "                    nonconformity(out, targets).detach().numpy())\n",
    "\n",
    "        self.calibration_scores = torch.tensor(calibration_scores).T\n",
    "\n",
    "        # Given p_{z}:=\\frac{\\left|\\left\\{i=m+1, \\ldots, n+1: R_{i} \\geq R_{n+1}\\right\\}\\right|}{n-m+1}\n",
    "        # and the accepted R_{n+1} = \\Delta(y, f(x_{test})) are such that\n",
    "        # p_{z} > \\alpha we have that the nonconformity scores should be below\n",
    "        # the (corrected) (1 - alpha)% of calibration scores.\n",
    "\n",
    "        # TODO check: By applying (3) to Zcal, we get the sequence of\n",
    "        # non-conformity scores and then sort them in descending order\n",
    "        # α1, . . . , αq. Then, depending on the significance level ε, we define\n",
    "        # the index of the (1 − ε)-percentile non-conformity score, αs, such as\n",
    "        # s = ⌊ε(q + 1)⌋.\n",
    "        self.critical_calibration_scores = torch.tensor([np.quantile(\n",
    "            position_calibration_scores, q=1 - self.alpha * self.num_train / (\n",
    "                    self.num_train + 1))\n",
    "            for position_calibration_scores in self.calibration_scores])\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Forecasts the time series with conformal uncertainty intervals.\"\"\"\n",
    "        out = self(x).squeeze()\n",
    "        # TODO +/- nonconformity will not return *adaptive* interval widths.\n",
    "        # TODO correction for multiple comparisons for each multi-horizon step.\n",
    "        return torch.vstack([out - self.critical_calibration_scores,\n",
    "                             out + self.critical_calibration_scores]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "macro-exemption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 100, 1]) torch.Size([1000, 10])\n",
      "torch.Size([1000, 100, 1]) torch.Size([1000, 10])\n",
      "torch.Size([100, 100, 1]) torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = generate_autoregressive_forecast_dataset(n_samples=1000, seq_len=100, horizon=10)\n",
    "calibration_dataset = generate_autoregressive_forecast_dataset(n_samples=1000, seq_len=100, horizon=10)\n",
    "test_dataset = generate_autoregressive_forecast_dataset(n_samples=100, seq_len=100, horizon=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: [n_samples, max_seq_len, n_features]\n",
    "# Y: [n_samples, horizon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sunset-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConformalForecaster(embedding_size=8, horizon=10, error_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "surprised-response",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'len_x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cd129ab61cea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalibration_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-0d48fc1ae505>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, calibration_dataset, epochs, lr, batch_size)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'len_x'"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, calibration_dataset, epochs=10, lr=0.01, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adequate-african",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.4111, 9.8009, 9.6471, 9.4183, 9.5524, 9.5123, 9.4077, 9.2933, 9.5192,\n",
       "        9.4380], dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.critical_calibration_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "pointed-mason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved coverage: 0.77\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "c = []\n",
    "for sequence, target in test_dataset:\n",
    "    sequence = sequence.unsqueeze(dim=0)\n",
    "    pred = model.predict(sequence)\n",
    "    c.append(cover(pred, target))\n",
    "print('Achieved coverage: {}'.format(np.mean(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "early-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cover(pred, target):\n",
    "    # Returns True when the entire forecast fits into predicted conformal\n",
    "    # intervals.\n",
    "    return torch.all(\n",
    "        torch.logical_and(target >= pred[:, 0], target <= pred[:, 1])).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "national-devil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 8])\n",
      "torch.Size([1, 10, 1, 1])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for sequence, target in test_dataset:\n",
    "    sequence = sequence.unsqueeze(dim=0)\n",
    "    h, _ = model.forecaster_rnn(sequence)\n",
    "    print(h.size())\n",
    "    # [batch, horizon, output_size, 1]\n",
    "    out = model.forecaster_out(h[:, -10:, :]).unsqueeze(-1)\n",
    "    print(out.size())\n",
    "    print(model.critical_calibration_scores.size())\n",
    "    print(out.squeeze().size())\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "accompanied-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "num_train = 1000\n",
    "\n",
    "def calibrate(calibration_dataset):\n",
    "    \"\"\"\n",
    "    Computes the nonconformity scores for the calibration dataset.\n",
    "    \"\"\"\n",
    "    calibration_loader = torch.utils.data.DataLoader(calibration_dataset,\n",
    "                                                     batch_size=1)\n",
    "    calibration_scores = []\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        model.eval()\n",
    "        for sequences, targets in calibration_loader:\n",
    "            out = model(sequences)\n",
    "            calibration_scores.extend(nonconformity(out, targets).detach().numpy())\n",
    "\n",
    "    calibration_scores = torch.tensor(calibration_scores).T\n",
    "\n",
    "    # Given p_{z}:=\\frac{\\left|\\left\\{i=m+1, \\ldots, n+1: R_{i} \\geq R_{n+1}\\right\\}\\right|}{n-m+1}\n",
    "    # and the accepted R_{n+1} = \\Delta(y, f(x_{test})) are such that\n",
    "    # p_{z} > \\alpha we have that the nonconformity scores should be below\n",
    "    # the (corrected) alpha% of calibration scores.\n",
    "    critical_calibration_scores = torch.tensor([np.quantile(\n",
    "        position_calibration_scores, q= alpha * num_train / (num_train + 1))\n",
    "        for position_calibration_scores in calibration_scores])\n",
    "    print(critical_calibration_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "threatened-token",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1335, 0.2231, 0.2458, 0.2786, 0.2465, 0.2878, 0.3393, 0.3049, 0.2977,\n",
      "        0.3465], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "calibrate(calibration_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "stylish-proceeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9500499500499501"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - alpha * num_train / (num_train + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "everyday-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def autoregressive(X_gen, w):\n",
    "    \"\"\" Generates a single time series example. \"\"\"\n",
    "    return np.array(\n",
    "        [np.sum(X_gen[0:k + 1] * np.flip(w[0:k + 1]).reshape(-1, 1)) for k in\n",
    "         range(len(X_gen))])\n",
    "\n",
    "\n",
    "seq_len = 10\n",
    "horizon = 10\n",
    "n_samples = 100\n",
    "X_mean = 1\n",
    "X_variance = 2\n",
    "n_features = 1\n",
    "memory_factor = 0.9\n",
    "\n",
    "# sequence_lengths = [seq_len + horizon] * n_samples\n",
    "sequence_lengths = range(horizon + 1, n_samples + horizon + 1)\n",
    "max_seq_len = np.max(sequence_lengths)\n",
    "\n",
    "# Create the input features of the generating process\n",
    "X_gen = [np.random.normal(X_mean, X_variance, (seq_len,\n",
    "                                               n_features))\n",
    "         for seq_len in sequence_lengths]\n",
    "\n",
    "# TODO determine how do weights and noise profile change depending on the\n",
    "# length of series.\n",
    "w = np.array([memory_factor ** k for k in range(max_seq_len)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "engaging-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_profiles = [[1 / (seq_len - 1) * k for k in range(max(1, seq_len))] for seq_len in sequence_lengths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "assisted-reward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_gen[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bored-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = [np.random.normal(0., noise_profile).reshape(-1, n_features) for noise_profile in noise_profiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "central-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = [autoregressive(X_gen[k], w).reshape(sequence_lengths[k], n_features) for k in range(n_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fresh-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = [torch.tensor(i + j) for i, j in zip(ar, noise)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "recovered-riverside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "touched-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "incorrect-january",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[autoregressive(X_gen[k], w).reshape(-1, n_features) for k in range(n_samples)][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "western-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "imposed-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "for seq in X_full:\n",
    "    seq_len = len(seq)\n",
    "    if seq_len >= 2 * horizon:\n",
    "        X.append(seq[:-horizon])\n",
    "        Y.append(seq[-horizon:])\n",
    "    elif seq_len > horizon:\n",
    "        X.append(seq[:seq_len - horizon])\n",
    "        Y.append(seq[-(seq_len - horizon):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "taken-concern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# for x in X:\n",
    "print(len(X[99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "environmental-floating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_full: 11\tX: 1\tY: 1\n",
      "X_full: 12\tX: 2\tY: 2\n",
      "X_full: 13\tX: 3\tY: 3\n",
      "X_full: 14\tX: 4\tY: 4\n",
      "X_full: 15\tX: 5\tY: 5\n",
      "X_full: 16\tX: 6\tY: 6\n",
      "X_full: 17\tX: 7\tY: 7\n",
      "X_full: 18\tX: 8\tY: 8\n",
      "X_full: 19\tX: 9\tY: 9\n",
      "X_full: 20\tX: 10\tY: 10\n",
      "X_full: 21\tX: 11\tY: 10\n",
      "X_full: 22\tX: 12\tY: 10\n",
      "X_full: 23\tX: 13\tY: 10\n",
      "X_full: 24\tX: 14\tY: 10\n",
      "X_full: 25\tX: 15\tY: 10\n",
      "X_full: 26\tX: 16\tY: 10\n",
      "X_full: 27\tX: 17\tY: 10\n",
      "X_full: 28\tX: 18\tY: 10\n",
      "X_full: 29\tX: 19\tY: 10\n",
      "X_full: 30\tX: 20\tY: 10\n",
      "X_full: 31\tX: 21\tY: 10\n",
      "X_full: 32\tX: 22\tY: 10\n",
      "X_full: 33\tX: 23\tY: 10\n",
      "X_full: 34\tX: 24\tY: 10\n",
      "X_full: 35\tX: 25\tY: 10\n",
      "X_full: 36\tX: 26\tY: 10\n",
      "X_full: 37\tX: 27\tY: 10\n",
      "X_full: 38\tX: 28\tY: 10\n",
      "X_full: 39\tX: 29\tY: 10\n",
      "X_full: 40\tX: 30\tY: 10\n",
      "X_full: 41\tX: 31\tY: 10\n",
      "X_full: 42\tX: 32\tY: 10\n",
      "X_full: 43\tX: 33\tY: 10\n",
      "X_full: 44\tX: 34\tY: 10\n",
      "X_full: 45\tX: 35\tY: 10\n",
      "X_full: 46\tX: 36\tY: 10\n",
      "X_full: 47\tX: 37\tY: 10\n",
      "X_full: 48\tX: 38\tY: 10\n",
      "X_full: 49\tX: 39\tY: 10\n",
      "X_full: 50\tX: 40\tY: 10\n",
      "X_full: 51\tX: 41\tY: 10\n",
      "X_full: 52\tX: 42\tY: 10\n",
      "X_full: 53\tX: 43\tY: 10\n",
      "X_full: 54\tX: 44\tY: 10\n",
      "X_full: 55\tX: 45\tY: 10\n",
      "X_full: 56\tX: 46\tY: 10\n",
      "X_full: 57\tX: 47\tY: 10\n",
      "X_full: 58\tX: 48\tY: 10\n",
      "X_full: 59\tX: 49\tY: 10\n",
      "X_full: 60\tX: 50\tY: 10\n",
      "X_full: 61\tX: 51\tY: 10\n",
      "X_full: 62\tX: 52\tY: 10\n",
      "X_full: 63\tX: 53\tY: 10\n",
      "X_full: 64\tX: 54\tY: 10\n",
      "X_full: 65\tX: 55\tY: 10\n",
      "X_full: 66\tX: 56\tY: 10\n",
      "X_full: 67\tX: 57\tY: 10\n",
      "X_full: 68\tX: 58\tY: 10\n",
      "X_full: 69\tX: 59\tY: 10\n",
      "X_full: 70\tX: 60\tY: 10\n",
      "X_full: 71\tX: 61\tY: 10\n",
      "X_full: 72\tX: 62\tY: 10\n",
      "X_full: 73\tX: 63\tY: 10\n",
      "X_full: 74\tX: 64\tY: 10\n",
      "X_full: 75\tX: 65\tY: 10\n",
      "X_full: 76\tX: 66\tY: 10\n",
      "X_full: 77\tX: 67\tY: 10\n",
      "X_full: 78\tX: 68\tY: 10\n",
      "X_full: 79\tX: 69\tY: 10\n",
      "X_full: 80\tX: 70\tY: 10\n",
      "X_full: 81\tX: 71\tY: 10\n",
      "X_full: 82\tX: 72\tY: 10\n",
      "X_full: 83\tX: 73\tY: 10\n",
      "X_full: 84\tX: 74\tY: 10\n",
      "X_full: 85\tX: 75\tY: 10\n",
      "X_full: 86\tX: 76\tY: 10\n",
      "X_full: 87\tX: 77\tY: 10\n",
      "X_full: 88\tX: 78\tY: 10\n",
      "X_full: 89\tX: 79\tY: 10\n",
      "X_full: 90\tX: 80\tY: 10\n",
      "X_full: 91\tX: 81\tY: 10\n",
      "X_full: 92\tX: 82\tY: 10\n",
      "X_full: 93\tX: 83\tY: 10\n",
      "X_full: 94\tX: 84\tY: 10\n",
      "X_full: 95\tX: 85\tY: 10\n",
      "X_full: 96\tX: 86\tY: 10\n",
      "X_full: 97\tX: 87\tY: 10\n",
      "X_full: 98\tX: 88\tY: 10\n",
      "X_full: 99\tX: 89\tY: 10\n",
      "X_full: 100\tX: 90\tY: 10\n",
      "X_full: 101\tX: 91\tY: 10\n",
      "X_full: 102\tX: 92\tY: 10\n",
      "X_full: 103\tX: 93\tY: 10\n",
      "X_full: 104\tX: 94\tY: 10\n",
      "X_full: 105\tX: 95\tY: 10\n",
      "X_full: 106\tX: 96\tY: 10\n",
      "X_full: 107\tX: 97\tY: 10\n",
      "X_full: 108\tX: 98\tY: 10\n",
      "X_full: 109\tX: 99\tY: 10\n",
      "X_full: 110\tX: 100\tY: 10\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    print('X_full: {}\\tX: {}\\tY: {}'.format(len(X_full[i]), len(X[i]), len(Y[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cultural-director",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "strategic-brooklyn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "neural-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.nn.utils.rnn.pad_sequence(X, batch_first=True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "finnish-tutorial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100, 1])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "hearing-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tensor = torch.nn.utils.rnn.pad_sequence(Y, batch_first=True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "automated-scott",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10, 1])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: [n_samples, max_seq_len, n_features]\n",
    "# Y: [n_samples, horizon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "joint-damages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(sequence_lengths).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "smaller-effectiveness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7fa6b6de9c10>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils.data.TensorDataset(X_tensor, Y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "signal-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoregressiveForecastDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Synthetic autoregressive forecast dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, X, Y, sequence_lengths):\n",
    "        super(AutoregressiveForecastDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.sequence_lengths = sequence_lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx], self.sequence_lengths[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "forced-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AutoregressiveForecastDataset(X_tensor, Y_tensor, sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "falling-power",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.AutoregressiveForecastDataset at 0x7fa6b6de3950>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "sharing-serum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fa6b7398c10>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=32,shuffle=False)\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "unnecessary-routine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.9074],\n",
      "         [ 0.0000],\n",
      "         [ 0.0000],\n",
      "         ...,\n",
      "         [ 0.0000],\n",
      "         [ 0.0000],\n",
      "         [ 0.0000]],\n",
      "\n",
      "        [[ 2.7737],\n",
      "         [ 2.2558],\n",
      "         [ 0.0000],\n",
      "         ...,\n",
      "         [ 0.0000],\n",
      "         [ 0.0000],\n",
      "         [ 0.0000]],\n",
      "\n",
      "        [[ 2.3862],\n",
      "         [ 4.2745],\n",
      "         [ 4.8667],\n",
      "         ...,\n",
      "         [ 0.0000],\n",
      "         [ 0.0000],\n",
      "         [ 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7812],\n",
      "         [ 0.2619],\n",
      "         [-1.1253],\n",
      "         ...,\n",
      "         [ 0.0000],\n",
      "         [ 0.0000],\n",
      "         [ 0.0000]],\n",
      "\n",
      "        [[-0.4307],\n",
      "         [ 0.2517],\n",
      "         [ 3.6385],\n",
      "         ...,\n",
      "         [ 0.0000],\n",
      "         [ 0.0000],\n",
      "         [ 0.0000]],\n",
      "\n",
      "        [[ 1.1731],\n",
      "         [-0.9770],\n",
      "         [ 0.1760],\n",
      "         ...,\n",
      "         [ 0.0000],\n",
      "         [ 0.0000],\n",
      "         [ 0.0000]]]) tensor([11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
      "        29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42])\n"
     ]
    }
   ],
   "source": [
    "for sequences, targets, lengths in train_loader:\n",
    "    print(sequences, lengths)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "indie-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_len, idx = lengths.sort(dim=0, descending=True)\n",
    "sorted_x = sequences[idx]\n",
    "\n",
    "# Convert to packed sequence batch\n",
    "packed_x = torch.nn.utils.rnn.pack_padded_sequence(sorted_x,\n",
    "                                                   lengths=sorted_len,\n",
    "                                                   batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "driving-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_h, _ = model.forecaster_rnn(packed_x.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "published-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = sequences.size(1)\n",
    "padded_out, _ = torch.nn.utils.rnn.pad_packed_sequence(packed_h,\n",
    "                                                       batch_first=True,\n",
    "                                                       total_length=max_seq_len)\n",
    "\n",
    "_, reverse_idx = idx.sort(dim=0, descending=False)\n",
    "padded_out = padded_out[reverse_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "binary-tunisia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 8])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "included-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 1])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 = model.forecaster_out(padded_out[:, -horizon:, :])\n",
    "out2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "blessed-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "spoken-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConformalForecaster(embedding_size=8, horizon=10, error_rate=0.05).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "creative-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, _ = model.forecaster_rnn(sequences.float())\n",
    "out1 = model.forecaster_out(out[:, -model.horizon:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "intense-authentication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 1])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "painful-vitamin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 1])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "sacred-alcohol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0559],\n",
       "        [0.0559],\n",
       "        [0.0559],\n",
       "        [0.0559],\n",
       "        [0.0559],\n",
       "        [0.0559],\n",
       "        [0.0559],\n",
       "        [0.0559],\n",
       "        [0.0559],\n",
       "        [0.0559]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "governing-alaska",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0459],\n",
       "        [0.0459],\n",
       "        [0.0459],\n",
       "        [0.0459],\n",
       "        [0.0459],\n",
       "        [0.0459],\n",
       "        [0.0459],\n",
       "        [0.0459],\n",
       "        [0.0459],\n",
       "        [0.0459]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "superb-bones",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[10.6410],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[ 5.5729],\n",
       "         [ 9.7845],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[11.3683],\n",
       "         [13.7080],\n",
       "         [13.8089],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[ 3.0774],\n",
       "         [ 6.5124],\n",
       "         [ 8.7384],\n",
       "         [10.0974],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[ 7.6234],\n",
       "         [ 5.8028],\n",
       "         [ 4.2828],\n",
       "         [ 5.1974],\n",
       "         [ 7.1386],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[ 5.6388],\n",
       "         [10.1000],\n",
       "         [10.4731],\n",
       "         [10.8238],\n",
       "         [14.7157],\n",
       "         [13.8110],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[ 5.7298],\n",
       "         [ 8.9837],\n",
       "         [ 8.5049],\n",
       "         [ 8.3998],\n",
       "         [ 7.0015],\n",
       "         [ 7.5742],\n",
       "         [ 5.9282],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[ 2.6927],\n",
       "         [ 2.1553],\n",
       "         [-1.0185],\n",
       "         [-0.5702],\n",
       "         [ 1.4357],\n",
       "         [-4.4038],\n",
       "         [-1.6407],\n",
       "         [-0.6384],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[11.7147],\n",
       "         [15.6683],\n",
       "         [14.0617],\n",
       "         [14.5895],\n",
       "         [15.0995],\n",
       "         [12.5838],\n",
       "         [11.2428],\n",
       "         [14.4484],\n",
       "         [13.1413],\n",
       "         [ 0.0000]],\n",
       "\n",
       "        [[10.5194],\n",
       "         [11.1476],\n",
       "         [11.9940],\n",
       "         [14.2779],\n",
       "         [15.1234],\n",
       "         [10.9826],\n",
       "         [ 7.2039],\n",
       "         [ 7.7686],\n",
       "         [11.4428],\n",
       "         [12.7137]],\n",
       "\n",
       "        [[ 2.2703],\n",
       "         [ 5.1204],\n",
       "         [ 5.3730],\n",
       "         [ 4.6313],\n",
       "         [ 7.4684],\n",
       "         [ 7.7395],\n",
       "         [10.1752],\n",
       "         [10.5152],\n",
       "         [ 8.4099],\n",
       "         [11.7247]],\n",
       "\n",
       "        [[14.1992],\n",
       "         [14.5172],\n",
       "         [15.4683],\n",
       "         [16.9727],\n",
       "         [14.3374],\n",
       "         [ 9.1737],\n",
       "         [13.4013],\n",
       "         [ 7.4130],\n",
       "         [ 8.1818],\n",
       "         [ 6.8175]],\n",
       "\n",
       "        [[ 5.1748],\n",
       "         [ 6.4169],\n",
       "         [ 2.6730],\n",
       "         [ 4.6360],\n",
       "         [ 6.5276],\n",
       "         [10.1913],\n",
       "         [ 8.2439],\n",
       "         [ 9.5285],\n",
       "         [ 7.7247],\n",
       "         [ 7.0428]],\n",
       "\n",
       "        [[ 9.1728],\n",
       "         [ 9.2074],\n",
       "         [ 8.0041],\n",
       "         [ 7.6237],\n",
       "         [11.1587],\n",
       "         [12.1526],\n",
       "         [13.8912],\n",
       "         [15.8933],\n",
       "         [16.1215],\n",
       "         [17.1347]],\n",
       "\n",
       "        [[ 6.4526],\n",
       "         [ 4.4888],\n",
       "         [ 3.7736],\n",
       "         [ 2.3192],\n",
       "         [ 4.4107],\n",
       "         [ 2.5096],\n",
       "         [ 3.3691],\n",
       "         [ 2.6538],\n",
       "         [ 3.0769],\n",
       "         [ 5.1162]],\n",
       "\n",
       "        [[15.2847],\n",
       "         [18.7778],\n",
       "         [19.0764],\n",
       "         [17.8723],\n",
       "         [15.0025],\n",
       "         [14.2068],\n",
       "         [13.6908],\n",
       "         [15.2456],\n",
       "         [20.7549],\n",
       "         [17.3075]],\n",
       "\n",
       "        [[ 7.0021],\n",
       "         [ 9.9258],\n",
       "         [10.2291],\n",
       "         [ 9.7811],\n",
       "         [ 9.8685],\n",
       "         [ 9.8964],\n",
       "         [ 6.7140],\n",
       "         [ 7.3958],\n",
       "         [ 7.4579],\n",
       "         [ 5.0947]],\n",
       "\n",
       "        [[11.6228],\n",
       "         [ 9.8513],\n",
       "         [ 9.7290],\n",
       "         [ 8.7196],\n",
       "         [10.1086],\n",
       "         [ 1.3858],\n",
       "         [ 3.2487],\n",
       "         [ 6.3177],\n",
       "         [ 8.7021],\n",
       "         [11.9297]],\n",
       "\n",
       "        [[ 8.5972],\n",
       "         [ 9.1475],\n",
       "         [10.5777],\n",
       "         [10.8013],\n",
       "         [ 5.7829],\n",
       "         [ 5.0148],\n",
       "         [ 5.9187],\n",
       "         [ 4.3216],\n",
       "         [ 6.9742],\n",
       "         [ 7.2656]],\n",
       "\n",
       "        [[-0.8607],\n",
       "         [ 5.4731],\n",
       "         [ 7.4716],\n",
       "         [ 6.0597],\n",
       "         [ 7.9986],\n",
       "         [ 6.6164],\n",
       "         [ 8.3725],\n",
       "         [10.4312],\n",
       "         [11.8520],\n",
       "         [11.6923]],\n",
       "\n",
       "        [[ 8.0374],\n",
       "         [ 6.5250],\n",
       "         [ 8.6480],\n",
       "         [10.2064],\n",
       "         [ 9.5425],\n",
       "         [11.3163],\n",
       "         [14.9111],\n",
       "         [13.0655],\n",
       "         [13.4018],\n",
       "         [14.3771]],\n",
       "\n",
       "        [[18.2747],\n",
       "         [19.1497],\n",
       "         [15.9892],\n",
       "         [12.9813],\n",
       "         [15.2499],\n",
       "         [14.4668],\n",
       "         [13.3822],\n",
       "         [13.2550],\n",
       "         [14.9192],\n",
       "         [13.9642]],\n",
       "\n",
       "        [[12.4797],\n",
       "         [10.7884],\n",
       "         [11.9279],\n",
       "         [ 9.3061],\n",
       "         [12.9295],\n",
       "         [15.2663],\n",
       "         [14.8116],\n",
       "         [16.0689],\n",
       "         [17.3602],\n",
       "         [15.9873]],\n",
       "\n",
       "        [[ 7.9973],\n",
       "         [ 8.4850],\n",
       "         [14.3902],\n",
       "         [11.0112],\n",
       "         [13.3244],\n",
       "         [14.6822],\n",
       "         [15.7784],\n",
       "         [ 9.8168],\n",
       "         [11.0545],\n",
       "         [17.1070]],\n",
       "\n",
       "        [[11.7553],\n",
       "         [14.8755],\n",
       "         [12.6064],\n",
       "         [15.1289],\n",
       "         [14.1249],\n",
       "         [12.4775],\n",
       "         [ 9.0158],\n",
       "         [10.3672],\n",
       "         [12.8421],\n",
       "         [10.8111]],\n",
       "\n",
       "        [[16.3478],\n",
       "         [13.0439],\n",
       "         [ 8.4653],\n",
       "         [ 5.4134],\n",
       "         [ 3.3381],\n",
       "         [ 6.5530],\n",
       "         [ 5.3737],\n",
       "         [ 6.9476],\n",
       "         [ 3.0225],\n",
       "         [ 5.4982]],\n",
       "\n",
       "        [[15.6322],\n",
       "         [13.1498],\n",
       "         [14.8555],\n",
       "         [12.3829],\n",
       "         [12.2511],\n",
       "         [12.0156],\n",
       "         [11.0884],\n",
       "         [10.3775],\n",
       "         [ 6.2297],\n",
       "         [ 8.2249]],\n",
       "\n",
       "        [[ 7.7995],\n",
       "         [10.0153],\n",
       "         [10.2637],\n",
       "         [ 8.5286],\n",
       "         [10.2423],\n",
       "         [12.3918],\n",
       "         [14.8038],\n",
       "         [10.2910],\n",
       "         [13.7062],\n",
       "         [13.1266]],\n",
       "\n",
       "        [[13.5792],\n",
       "         [11.0764],\n",
       "         [12.4120],\n",
       "         [ 8.1989],\n",
       "         [ 7.3324],\n",
       "         [ 3.3066],\n",
       "         [ 4.4731],\n",
       "         [ 5.8454],\n",
       "         [ 9.4541],\n",
       "         [ 3.7578]],\n",
       "\n",
       "        [[ 7.7696],\n",
       "         [ 6.9427],\n",
       "         [ 8.9027],\n",
       "         [ 9.2919],\n",
       "         [ 6.9328],\n",
       "         [ 9.9709],\n",
       "         [ 9.5780],\n",
       "         [ 9.6009],\n",
       "         [ 7.8028],\n",
       "         [ 7.2662]],\n",
       "\n",
       "        [[ 5.9886],\n",
       "         [ 6.5658],\n",
       "         [10.6146],\n",
       "         [ 7.3933],\n",
       "         [ 4.2979],\n",
       "         [ 5.8886],\n",
       "         [ 6.2242],\n",
       "         [ 4.8426],\n",
       "         [ 6.5448],\n",
       "         [10.5865]],\n",
       "\n",
       "        [[14.9800],\n",
       "         [11.7492],\n",
       "         [10.7957],\n",
       "         [11.7008],\n",
       "         [12.4930],\n",
       "         [14.7827],\n",
       "         [12.0531],\n",
       "         [11.6637],\n",
       "         [ 9.3715],\n",
       "         [12.4761]]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "heavy-equivalent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "consolidated-burning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 1])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "outer-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_mask = torch.zeros(targets.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "intimate-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, l in enumerate(lengths):\n",
    "    lengths_mask[i, :min(l, horizon), :] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "sharing-ending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(96.5020, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.mse_loss(lengths_mask * out2, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "binary-precipitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3333)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.mse_loss(torch.tensor([1.,2.,3.]), torch.tensor([1.,0.,3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "subjective-expert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0459],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0000],\n",
       "         [0.0000]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0000]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]],\n",
       "\n",
       "        [[0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459],\n",
       "         [0.0459]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths_mask * out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "placed-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConformalForecaster(torch.nn.Module):\n",
    "    def __init__(self, embedding_size, input_size=1, output_size=1, horizon=1,\n",
    "                 error_rate=0.05):\n",
    "        super(ConformalForecaster, self).__init__()\n",
    "        # input_size indicates the number of features in the time series\n",
    "        # input_size=1 for univariate series.\n",
    "\n",
    "        # Encoder and forecaster can be the same (if embeddings are\n",
    "        # trained on `horizon`-step forecasts), but different models are\n",
    "        # possible.\n",
    "\n",
    "        # TODO try separate encoder and forecaster models.\n",
    "        # TODO try the RNN autoencoder trained on reconstruction error.\n",
    "        self.encoder = None\n",
    "\n",
    "        self.forecaster_rnn = torch.nn.LSTM(input_size=input_size,\n",
    "                                            hidden_size=embedding_size,\n",
    "                                            batch_first=True)\n",
    "        self.forecaster_out = torch.nn.Linear(embedding_size, output_size)\n",
    "\n",
    "        self.horizon = horizon\n",
    "        self.alpha = error_rate\n",
    "\n",
    "        self.n_train = None\n",
    "        self.calibration_scores = None\n",
    "        self.critical_calibration_scores = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.forecaster_rnn(x)\n",
    "        # [batch, horizon, output_size, 1]\n",
    "        out = self.forecaster_out(\n",
    "            out[:, -self.horizon:, :]).unsqueeze(-1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def fit(self, dataset, calibration_dataset, epochs, lr, batch_size=150):\n",
    "        # Train the forecaster to return correct multi-step predictions.\n",
    "        train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True)\n",
    "        self.n_train = len(dataset)\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = 0.\n",
    "\n",
    "            # Iterate through batches.\n",
    "            for sequences, targets, lengths in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                out = self(sequences, lengths)\n",
    "\n",
    "                loss = criterion(out, targets)\n",
    "                loss.backward()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "            mean_train_loss = train_loss / len(train_loader)\n",
    "            if epoch % 50 == 0:\n",
    "                print(\n",
    "                    'Epoch: {}\\tTrain loss: {}'.format(epoch, mean_train_loss))\n",
    "\n",
    "        # Collect calibration scores\n",
    "        self.calibrate(calibration_dataset)\n",
    "\n",
    "    def calibrate(self, calibration_dataset):\n",
    "        \"\"\"\n",
    "        Computes the nonconformity scores for the calibration dataset.\n",
    "        \"\"\"\n",
    "        calibration_loader = torch.utils.data.DataLoader(calibration_dataset,\n",
    "                                                         batch_size=1)\n",
    "        calibration_scores = []\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            self.eval()\n",
    "            for sequences, targets in calibration_loader:\n",
    "                out = self(sequences)\n",
    "                calibration_scores.extend(\n",
    "                    nonconformity(out, targets).detach().numpy())\n",
    "\n",
    "        self.calibration_scores = torch.tensor(calibration_scores).T\n",
    "\n",
    "        # Given p_{z}:=\\frac{\\left|\\left\\{i=m+1, \\ldots, n+1: R_{i} \\geq R_{n+1}\\right\\}\\right|}{n-m+1}\n",
    "        # and the accepted R_{n+1} = \\Delta(y, f(x_{test})) are such that\n",
    "        # p_{z} > \\alpha we have that the nonconformity scores should be below\n",
    "        # the (corrected) (1 - alpha)% of calibration scores.\n",
    "\n",
    "        # TODO check: By applying (3) to Zcal, we get the sequence of\n",
    "        # non-conformity scores and then sort them in descending order\n",
    "        # α1, . . . , αq. Then, depending on the significance level ε, we define\n",
    "        # the index of the (1 − ε)-percentile non-conformity score, αs, such as\n",
    "        # s = ⌊ε(q + 1)⌋.\n",
    "        self.critical_calibration_scores = torch.tensor([np.quantile(\n",
    "            position_calibration_scores, q=1 - self.alpha * self.n_train / (\n",
    "                    self.n_train + 1))\n",
    "            for position_calibration_scores in self.calibration_scores])\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Forecasts the time series with conformal uncertainty intervals.\"\"\"\n",
    "        out = self(x).squeeze()\n",
    "        # TODO +/- nonconformity will not return *adaptive* interval widths.\n",
    "        # TODO correction for multiple comparisons for each multi-horizon step.\n",
    "        return torch.vstack([out - self.critical_calibration_scores,\n",
    "                             out + self.critical_calibration_scores]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "stupid-banking",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-a6b372980608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecaster_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/aml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 662\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "model.forecaster_rnn(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cooked-fraction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 1])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-fetish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
